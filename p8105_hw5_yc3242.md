p8105\_hw5\_yc3242
================
Youn Kyeong Chang (uni\# yc3242)
November 7, 2018

``` r
library(tidyverse)
```

    ## -- Attaching packages ------------------------------------------- tidyverse 1.2.1 --

    ## v ggplot2 3.0.0     v purrr   0.2.5
    ## v tibble  1.4.2     v dplyr   0.7.6
    ## v tidyr   0.8.1     v stringr 1.3.1
    ## v readr   1.1.1     v forcats 0.3.0

    ## -- Conflicts ---------------------------------------------- tidyverse_conflicts() --
    ## x dplyr::filter() masks stats::filter()
    ## x dplyr::lag()    masks stats::lag()

### Problem 1

#### 1-(1)

: Create a tidy dataframe containing data from all pariticipants, including the subject ID, arm, and observations over time.

``` r
# Started with a dataframe containing all file names
study_data = 
  tibble(file_names = list.files(path = "data/", full.names = T))

# Iterated over file names and read in data for each subject and saved them as a data variable in the dataframe
study_data$data =
  map(study_data$file_names, read_csv)

# Tidied data 
study_data =
  study_data %>% 
  unnest() %>% 
  separate(file_names, into = c("arm", "id"), sep = "_") %>% 
  mutate(arm = str_remove(arm, "data/"),
         id = str_remove(id, ".csv")) %>% 
  gather(key = "week", value = "obs", "week_1":"week_8") %>% 
  mutate(week = as.numeric(str_remove(week, "week_")))
```

#### 1-(2)

: Spaghetti plot showing observations on each subject over time.

``` r
study_data %>% 
  ggplot(aes(x = week, y = obs, group = id)) +
  geom_line(aes(color = arm), size = 1) +
  labs(
    title = "Observations on each subject over time",
    y = "observation"
  ) +
  facet_grid(~ arm) +
  stat_summary(aes(group = arm), fun.y = "mean", geom = "point", 
               color = "blue", size = 3, shape = 17) +
  theme(plot.title = element_text(size = 12),
        strip.background = element_rect(fill = "black"),
        strip.text = element_text(color = "white", face = "bold")) 
```

![](p8105_hw5_yc3242_files/figure-markdown_github/plot_study_data-1.png)

``` r
study_data %>% 
  group_by(arm, id) %>% 
  ggplot(aes(x = week, y = obs, color = arm, type = id)) +
  geom_line() +
  stat_summary(aes(group = arm), fun.y = "mean", geom = "line", color = "blue") 
```

![](p8105_hw5_yc3242_files/figure-markdown_github/unnamed-chunk-2-1.png)

Average observation is similar at starting point week 0 but over time, average observation in control group remains constant while in exosure group is increasing.

### Problem 2

#### 2-(1)

: load and describe raw data.

``` r
homicide_data = 
  read_csv("https://raw.githubusercontent.com/washingtonpost/data-homicides/master/homicide-data.csv") %>% 
  janitor::clean_names()
```

    ## Parsed with column specification:
    ## cols(
    ##   uid = col_character(),
    ##   reported_date = col_integer(),
    ##   victim_last = col_character(),
    ##   victim_first = col_character(),
    ##   victim_race = col_character(),
    ##   victim_age = col_character(),
    ##   victim_sex = col_character(),
    ##   city = col_character(),
    ##   state = col_character(),
    ##   lat = col_double(),
    ##   lon = col_double(),
    ##   disposition = col_character()
    ## )

The data consists of 52179 observations and 12 variables as follows:

-   `uid`: report identifier
-   `reported_date`: reported date
-   `victim_last`: Last name of victim
-   `victim_first`: First name of victim
-   `victim_race`: Race of victim
-   `victim_age`: Age of victim
-   `victim_sex`: Sex of victim
-   `city`: city of homicide
-   `state`: State of homicide
-   `lat`: latitude of homicide
-   `lon`: longitude of homicide
-   `disposition`: Case classification

#### 2-(2)

: Create a city\_state variable.

``` r
homicide_data = 
  homicide_data %>% 
  unite(city_state, city, state, sep = ",") %>% 
  mutate(city_state = recode(city_state, "Tulsa,AL" = "Tulsa,OK")) 
```

#### 2-(3)

: Total number of homicide and the number of unsolved homicides.

``` r
ttl_unsol = 
homicide_data %>%
  group_by(city_state) %>% 
  summarize(total = n(), 
            unsolved = sum(disposition %in% c("Closed without arrest", "Open/No arrest")))

ttl_unsol
```

    ## # A tibble: 50 x 3
    ##    city_state     total unsolved
    ##    <chr>          <int>    <int>
    ##  1 Albuquerque,NM   378      146
    ##  2 Atlanta,GA       973      373
    ##  3 Baltimore,MD    2827     1825
    ##  4 Baton Rouge,LA   424      196
    ##  5 Birmingham,AL    800      347
    ##  6 Boston,MA        614      310
    ##  7 Buffalo,NY       521      319
    ##  8 Charlotte,NC     687      206
    ##  9 Chicago,IL      5535     4073
    ## 10 Cincinnati,OH    694      309
    ## # ... with 40 more rows

#### 2-(4)

: For the city of Baltimore, MD, estimate the proportion of homicides that are unsolved.

``` r
prop_unsol = function(city) {
  
  city = ttl_unsol %>% 
    filter(city_state == city)
  
  prop_city = prop.test(city$unsolved, city$total)

  broom::tidy(prop_city) %>% 
  select(estimate, conf.low, conf.high)
}

prop_unsol("Baltimore,MD")
```

    ## # A tibble: 1 x 3
    ##   estimate conf.low conf.high
    ##      <dbl>    <dbl>     <dbl>
    ## 1    0.646    0.628     0.663

``` r
prop_unsol = function(city) {
  
  city = 
    ttl_unsol %>% 
    filter(city_state == city)
  
  prop.test(city$unsolved, city$total)

}

tidy_prop_unsol = function(x) {
  broom::tidy(x) %>% 
  select(estimate, conf.low, conf.high)
}
```

### 2-(5)

: proportion of unsolved homicides for each of the cities

Now run prop.test for each of the cities in your dataset, and extract both the proportion of unsolved homicides and the confidence interval for each. Do this within a “tidy” pipeline, making use of purrr::map, purrr::map2, list columns and unnest as necessary to create a tidy dataframe with estimated proportions and CIs for each city.

Create a plot that shows the estimates and CIs for each city – check out geom\_errorbar for a way to add error bars based on the upper and lower limits. Organize cities according to the proportion of unsolved homicides.
